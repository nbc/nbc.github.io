---
title: "Pourquoi éviter arrow::to_arrow() avec DuckDB + dplyr"
description: "Pourquoi utiliser `arrow::to_arrow` est une mauvaise idée avec `dplyr::tbl`"
date: 2025-07-11
categories: [duckdb, arrow]
image: https://duckplyr.tidyverse.org/logo.png 
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

Une syntaxe souvent recommandée pour écrire un fichier parquet après des ordres `dplyr::tbl` est d'utiliser `arrow::to_arrow` avec `arrow::write_dataset` ou `arrow::write_parquet` :

```{r}
#| eval: false
tbl(con, "read_parquet('geo.parquet')") |>
  ...
  arrow::to_arrow() |>
  arrow::write_dataset("mon_dataset")
```

Cette syntaxe fonctionne toujours mais le nouveau package [duckplyr](https://duckplyr.tidyverse.org/index.html) propose une méthode beaucoup plus efficace :

```{r}
#| eval: false
con <- dbConnect(duckdb())

tbl(con, "read_parquet('geo.parquet')") |>
  ...
  duckplyr::as_duckdb_tibble() |> # <1>
  duckplyr::compute_parquet("my_tbl.parquet") # <2>
```  

1. converti l'objet retourné par `tbl` en objet lisible par `duckplyr`
2. écrit le fichier parquet

Les deux lignes fonctionnent de la même façon que celle de `arrow` en étant **beaucoup plus efficace**.

## Une comparaison rapide

Voici les résultats de tests de différentes façons de faire classiques (et le code pour les relancer chez vous ci-dessous) :

- `with_arrow` : la méthode utilisant `arrow`
- `with_duckplyr` : la méthode utilisant `duckplyr`
- `with_copy_to` : la méthode utilisant le `COPY ... TO ...` de `duckdb` à titre de comparaison

```{r}
#| warning: false
#| code-fold: true
#| code-summary: "Montre moi le code du benchmark"
library(duckdb)
library(dplyr)
library(arrow)
# pour afficher
library(kableExtra)
# un outil de benchmark
library(timemoir)

if (!file.exists("geo.parquet")) {
  download.file("https://static.data.gouv.fr/resources/sirene-geolocalise-parquet/20240107-143656/sirene2024-geo.parquet", "geo.parquet")
}

# la version full duckdb
with_copy_to <- function() {
  con <- dbConnect(duckdb())
  on.exit(dbDisconnect(con, shutdown = TRUE))
  
  dbExecute(con, "COPY (FROM read_parquet('geo.parquet')) TO 'test.parquet' (FORMAT PARQUET, COMPRESSION ZSTD)")
}

# La version `"historique" avec `arrow` :
with_arrow <- function() {
  con <- dbConnect(duckdb())
  on.exit(dbDisconnect(con, shutdown = TRUE))

  tbl(con, "read_parquet('geo.parquet')") |>
    arrow::to_arrow() |>
    arrow::write_dataset('test', compression='zstd')
}

# Et la même en utilisant le nouveau package duckplyr :
with_duckplyr <- function() {
  con <- dbConnect(duckdb())
  on.exit(dbDisconnect(con, shutdown = TRUE))

  tbl(con, "read_parquet('geo.parquet')") |>
    duckplyr::as_duckdb_tibble() |>
    duckplyr::compute_parquet("my_tbl.parquet")
}
```

```{r}
#| label: output_benchmark
#| cache: true
res <- timemoir(
  with_arrow(), 
  with_copy_to(), 
  with_duckplyr()
)

res |>
  kableExtra::kable()
plot(res)
```

---

Sur le serveur que j'utilise, la version `duckplyr` est **6 fois plus rapide** que la version `arrow` et consomme **deux fois moins de mémoire**, à égalité avec la méthode pure duckdb.

## Conclusion

Si vous utilisez dplyr, arrêtez d'utiliser `to_arrow` et passez à `duckplyr`

## Quelques liens

* la [documentation de duckplyr](https://duckplyr.tidyverse.org/articles/large.html)

---

::: {.callout-note collapse=true}
## Information de session
```{r}
#| label: session_info
devtools::session_info(pkgs = "attached")
```
:::