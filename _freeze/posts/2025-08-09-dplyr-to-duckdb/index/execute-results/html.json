{
  "hash": "26e2c1e62de72bc6a2c50db281a13394",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Convertir un traitement dplyr en duckdb\"\ndescription: \"Pourquoi éviter arrow::to_arrow() avec DuckDB + dplyr\"\ndate: 2025-08-09\ncategories: [R, duckdb, arrow]\nimage: https://duckplyr.tidyverse.org/logo.png \ndraft: true\n---\n\n## Présentation du cas\n\nCe cas pratique vient du transport. Il sert à préparer des fichiers d'étude à\npartir de deux jeux de données :\n\n* vehicule : les propriétés  d'un véhicule (immat, cylindrée, énergie, date de mise en circulation...) fait 70 millions de lignes\n* annee : les évènements liés à un véhicule par année (km parcouru, présence dans le parc... ) fait 490 millions de lignes\n\nEt d'une troisième table de 50 lignes avec la nomenclature des carburants.\n\nDans le code d'origine, afin de tenir sur le serveur, les données vehicule et\nannee d'origine sont partitionnées à la main en 10 fichiers véhicules et 10\nfichiers années correspondants pour générer 10 fichiers d'étude.\n\nLe traitement actuel est le suivant :\n\n1. charge deux fichiers de données parquet en mémoire avec `arrow::read_parquet()\n1. fait une jointure entre les deux fichiers de données avec `dplyr`\n1. ajoute des colonnes calculées toujours avec `dplyr` (année de mise en circulation à partir de la date, la quantité de CO2 émise par tranche...)\n1. écrit le fichier résultat\n\nNotre cas pratique reprend uniquement la génération d'un fichier d'étude sur les 10.\n\nDans le suite, nous allons rapidement présenter le code d'origine et voir les\ndifférentes évolutions possibles.\n\n## Le code d'origine\n\nLe programme d'origine utilise `arrow` uniquement pour la lecture des données au\nformat parquet. Les calculs sont réalisés avec `dplyr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"arrow\")\nlibrary(\"dplyr\")\nlibrary(\"readxl\")\nlibrary(\"writexl\")\nlibrary(tictoc)\nlibrary(\"data.table\")\n\n\nchemin_donnees_sources <- \"/home/nc/projet/Parc/\"\n\ngrille_carbu <- subset(\n  read_xlsx(\"/home/nc/projet/Nomenclature/Vehicule/nomenclature_carburant_mai_2022.xlsx\"),\n  select=c(carbu_simpl,carbu_det,energ))\n\n### Boucle pour préparer et exporter toutes les tables data_etude_0 à data_etude_9. ###\n\ndata <- left_join(read_parquet(paste0(chemin_donnees_sources,\"data_annee_VP_0.parquet\"),\n                               col_select = c(\"id\",\"year\",\"parc_01_01\",\"parcm\",\"km\")),\n                  read_parquet(paste0(chemin_donnees_sources,\"data_vehicule_VP_0.parquet\"),\n                               col_select = c(\"id\",\"date_mise_en_cir\",\"energ\",\"co2_theorique\",\n                                              \"puis_kw\",\"poids_vide\",\"crit_air\",\"conso_reelle\",\n                                              \"co2_reel\"))\n                  ,by=\"id\") %>%\n  filter(year>=2012) %>%\n  mutate(\n    poids_vide_tr = cut(poids_vide,\n                        breaks=c(min(poids_vide,na.rm=TRUE),1000,1200,1500,1800,2000,\n                                 max(poids_vide,na.rm=TRUE)),\n                        include.lowest=TRUE,\n                        labels=c(\"1 - moins de 1000 kg\",\n                                 \"2 - plus de 1 à 1,2 t\",\n                                 \"3 - plus de 1,2 à 1,5 t\",\n                                 \"4 - plus de 1,5 à 1,8 t\",\n                                 \"5 - plus de 1,8 à 2 t\",\n                                 \"6 - plus de 2 t\")),\n    annee_mise_en_cir = as.numeric(substr(date_mise_en_cir,1,4)),\n    age = as.numeric(difftime(as.IDate(paste0(year,\"-01-01\")),date_mise_en_cir,units=\"days\")/365.25),\n    age_tr = cut(age,\n                 breaks=c(min(age,na.rm=TRUE),2,5,10,15,20,25,max(age,na.rm=TRUE)),\n                 include.lowest=TRUE,\n                 labels=c(\"1 - moins de 2 ans\",\n                          \"2 - plus de 2 à 5 ans\",\n                          \"3 - plus de 5 à 10 ans\",\n                          \"4 - plus de 10 à 15 ans\",\n                          \"5 - plus de 15 à 20 ans\",\n                          \"6 - plus de 20 à 25 ans\",\n                          \"7 - plus de 25 ans\")),\n    co2_reel = as.numeric(co2_reel),\n    co2_reel_tr = cut(co2_reel,\n                      breaks=c(min(co2_reel,na.rm=TRUE),125,150,175,200,max(co2_reel,na.rm=TRUE)),\n                      include.lowest=TRUE,\n                      labels=c(\"1 - moins de 125 g/km\",\n                               \"2 - plus de 125 à 150 g/km\",\n                               \"3 - plus de 150 à 175 g/km\",\n                               \"4 - plus de 175 à 200 g/km\",\n                               \"5 - plus de 200 g/km\")),\n    co2_reel_tr = ifelse(crit_air==\"E\",\"0 - véhicule électrique\",co2_reel_tr),\n    co2_reel_tr = ifelse(is.na(co2_reel_tr),\"NA - inconnu\",co2_reel_tr),\n    co2_theorique = as.numeric(co2_theorique),\n    co2_theorique_tr = cut(co2_theorique,\n                           breaks=c(min(co2_theorique,na.rm=TRUE),125,150,175,200,\n                                    max(co2_theorique,na.rm=TRUE)),\n                           include.lowest=TRUE,\n                           labels=c(\"1 - moins de 125 g/km\",\n                                    \"2 - plus de 125 à 150 g/km\",\n                                    \"3 - plus de 150 à 175 g/km\",\n                                    \"4 - plus de 175 à 200 g/km\",\n                                    \"5 - plus de 200 g/km\")),\n    co2_theorique_tr = ifelse(crit_air==\"E\",\"0 - véhicule électrique\",co2_theorique_tr),\n    co2_theorique_tr = ifelse(is.na(co2_theorique_tr),\"NA - inconnu\",co2_theorique_tr),\n    puis_kw_tr = cut(puis_kw,\n                     breaks=c(min(puis_kw,na.rm=TRUE),55,70,85,100,max(puis_kw,na.rm=TRUE)),\n                     include.lowest=TRUE,\n                     labels=c(\"1 - moins de 55 kw\",\n                              \"2 - plus de 55 à 70 kw\",\n                              \"3 - plus de 70 à 85 kw\",\n                              \"4 - plus de 85 à 100 kw\",\n                              \"5 - plus de 100 kw\")),\n    puis_kw_tr = ifelse(is.na(puis_kw_tr),\"NA - inconnu\",puis_kw_tr)\n  ) %>%\n\n  left_join(grille_carbu,by=\"energ\") %>%\n\n  mutate(\n    carbu_agreg = ifelse(carbu_det %in% c(\"Diesel\",\"Biodiesel\",\"Diesel HNR\",\"Diesel HR\"),\n                         \"Diesel (y compris hybrides)\",\n                         \"Essence et autres énergies\"),\n    carbu_agreg2 = ifelse(carbu_simpl %in% c(\"Diesel\",\"Essence\"),\n                          \"Diesel et Essence thermiques\",\n                          \"Autres énergies\")\n  )\n\nwrite_parquet(data, \"origine.parquet\")\n```\n:::\n\n\n::: {.callout-note}\nLe code fonctionne parfaitement et le temps de traitement est de l'ordre de\n15min pour une consommation en pic 25Go de mémoire.\n:::\n\nIl pourrait certainement être optimisé, le `mutate` réalisé à la fin pourrait\nl'être directement sur la table grille_carbu au début pour éviter de devoir\nmodifier les millions de lignes mais ça restera de l'optimisation à la marge (test\nfait, le traitement passe à 12min).\n\nLes principaux problèmes de ce code, (écrit à une époque ou `arrow` n'était pas\nencore vraiment utilisable sur nos serveurs) sont que :\n\n* les données sont entièrement chargées en mémoire par `arrow::read_parquet()`\n* les calculs sont réalisés par `dplyr` qui n'est pas connu pour être rapide\n\nSi ça ne pose pas de problème sur quelques milliers voire centaines de milliers\nde lignes, ça devient rédhibitoire quand on croise des dizaines de millions de\nlignes.\n\n## Première étape : utilisation de `duckdb` et `dplyr`\n\nDans cette première étape, nous allons essayer d'éviter de charger les données\ndans R et, surtout, de faire la jointure en mémoire. Pour cela nous allons lire\nles données avec `duckdb` et les traiter avec `dplyr` qui, en sous-main, va\nutiliser `dbplyr` (la version de `dplyr` pour les bases de données).\n\n\n### L'initialisation\n\nNous allons commencer par charger les packages nécessaires et on créé une\nvariable avec les chemins :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(tictoc)\n\nchemin_donnees_sources <- \"/home/nc/projet/Parc/Parc_2022/Donnees_individuelles/\"\n```\n:::\n\n\nPuis nous créons une base de données dans le fichier `test.duckdb`, on limite la\nmémoire à 10Go et le nombre de CPU utilisé à 4 pour ne pas écrouler le serveur.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- DBI::dbConnect(duckdb(), dbdir = \"test.duckdb\",            \n                      config=list(\"memory_limit\"=\"10GB\",\n                                  \"threads=4\"))\n```\n:::\n\n\n### Création des tables de base de données à utiliser\n\nLe référentiel des carburants n'étant pas un fichier parquet, on écrit les\ndonnées dans la base avec la commande `DBI::dbWriteTable()`\n\nOn créé les objets `vehicule`, `annee` et `grille_carbu` avec `dplyr::tbl()`,\ncette fonction transforme une table de base de données ou un fichier parquet en\nobjet utilisable par `dplyr`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_xlsx(\"/home/nc/projet/Nomenclature/Vehicule/nomenclature_carburant_mai_2022.xlsx\") |>\n  select(carbu_simpl,carbu_det,energ) |>\n  dbWriteTable(con, \"grille_carbu\", value = _, overwrite = TRUE)\ngrille_carbu <- tbl(con, \"grille_carbu\")\n\nvehicule <- tbl(con, file.path(chemin_donnees_sources, \"data_vehicule_VP_0.parquet\")) %>%\n  select(id, date_mise_en_cir,energ, co2_theorique,puis_kw,poids_vide,crit_air,conso_reelle,co2_reel)\n\nannee <- tbl(con, file.path(chemin_donnees_sources, \"data_annee_VP_0.parquet\")) %>%\n  select(id, year, parc_01_01, parcm, km)\n```\n:::\n\n\n### Création de la requête `dbplyr`\n\nJ'ai pris le parti de modifier le code d'origine à minima pour qu'il fonctionne\navec `dbplyr`, les modifications sont à trois niveaux :\n\n* changer les bornes des `cut` pour les passer à `0` et `Inf` plutôt que de calculer les min et max\n* utiliser `lubridate::year()` plutôt que `as.numeric(substr(date_mise_en_cir,1,4))` (ligne 5)\n* utiliser `lubridate::as_date()` pour calculer l'age du véhicule (ligne 6)\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nrequest <- vehicule %>%\n  right_join(annee, by = c(\"id\")) %>%\n  filter(year >= 2012) %>%\n  mutate(\n    annee_mise_en_cir = year(date_mise_en_cir),\n    age = (as_date(paste0(year, \"-01-01\")) - date_mise_en_cir ) / 365.25,\n    poids_vide_tr = cut(poids_vide,\n                      breaks=c(0,1000,1200,1500,1800,2000,Inf),\n                      include.lowest=TRUE,\n                      labels=c(\"1 - moins de 1000 kg\",\n                               \"2 - plus de 1 à 1,2 t\",\n                               \"3 - plus de 1,2 à 1,5 t\",\n                               \"4 - plus de 1,5 à 1,8 t\",\n                               \"5 - plus de 1,8 à 2 t\",\n                               \"6 - plus de 2 t\")),\n    age_tr = cut(age,\n                 breaks=c(0,2,5,10,15,20,25,Inf),\n                 include.lowest=TRUE,\n                 labels=c(\"1 - moins de 2 ans\",\n                          \"2 - plus de 2 à 5 ans\",\n                          \"3 - plus de 5 à 10 ans\",\n                          \"4 - plus de 10 à 15 ans\",\n                          \"5 - plus de 15 à 20 ans\",\n                          \"6 - plus de 20 à 25 ans\",\n                          \"7 - plus de 25 ans\")),\n    co2_reel_tr = cut(co2_reel,\n                      breaks=c(0,100,130,140,155,175,200,Inf),\n                      include.lowest=TRUE,\n                      labels=c(\"1 - moins de 123 g/km\",\n                               \"2 - plus de 123 à 138 g/km\",\n                               \"3 - plus de 138 à 165 g/km\",\n                               \"4 - plus de 165 à 190 g/km\",\n                               \"5 - plus de 190 à 213 g/km\",\n                               \"6 - plus de 213 à 226 g/km\",\n                               \"7 - plus de 226 g/km\")),\n    co2_reel_tr = ifelse(crit_air==\"E\",\"0 - véhicule électrique\",co2_reel_tr),\n    co2_reel_tr = ifelse(is.na(co2_reel_tr),\"NA - inconnu\",co2_reel_tr),\n    co2_theorique_tr = cut(co2_theorique,\n                           breaks=c(0,123,138,165,190,213,226,Inf),\n                           include.lowest=TRUE,\n                           labels=c(\"1 - moins de 123 g/km\",\n                                    \"2 - plus de 123 à 138 g/km\",\n                                    \"3 - plus de 138 à 165 g/km\",\n                                    \"4 - plus de 165 à 190 g/km\",\n                                    \"5 - plus de 190 à 213 g/km\",\n                                    \"6 - plus de 213 à 226 g/km\",\n                                    \"7 - plus de 226 g/km\")),\n    co2_theorique_tr = ifelse(crit_air==\"E\",\"0 - véhicule électrique\",co2_theorique_tr),\n    co2_theorique_tr = ifelse(is.na(co2_theorique_tr),\"NA - inconnu\",co2_theorique_tr),\n    puis_kw_tr = cut(puis_kw,\n                     breaks=c(0,55,70,85,100,Inf),\n                     include.lowest=TRUE,\n                     labels=c(\"1 - moins de 55 kw\",\n                              \"2 - plus de 55 à 70 kw\",\n                              \"3 - plus de 70 à 85 kw\",\n                              \"4 - plus de 85 à 100 kw\",\n                              \"5 - plus de 100 kw\"))\n    ) %>%\n  left_join(grille_carbu, by = \"energ\") %>%\n  mutate(\n    carbu_agreg = ifelse(carbu_det %in% c(\"Diesel\",\"Biodiesel\",\"Diesel HNR\",\"Diesel HR\"),\n                         \"Diesel (y compris hybrides)\",\n                         \"Essence et autres énergies\"),\n    carbu_agreg2 = ifelse(carbu_simpl %in% c(\"Diesel\",\"Essence\"),\n                          \"Diesel et Essence thermiques\",\n                          \"Autres énergies\")\n  )\n```\n:::\n\n\nCette commande retourne (quasiment) immédiatement car à ce stade, l'objet request\nn'est pas encore évalué, on parle de \"lazy evaluation\", il contient juste les\nordres à passer.\n\n### on exécute la requête\n\nLa requête est effectivement exécuté au moment de la commande `write_parquet()`,\n`dbplyr` va alors transformer tous les ordres en SQL et les envoyer à la base de\ndonnées.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequest %>%\n  to_arrow() %>%\n  write_parquet(\"dbplyr.parquet\")\n```\n:::\n\n\n::: {.callout-note}\nCe code prend autour de 150 secondes et consomme au pic 15/16Go de mémoire.\n:::\n\n::: {.callout-tip}\nLa limite à 10Go de `duckdb` ne fonctionne visiblement pas, pourquoi ? \n\nUne partie de la mémoire est utilisée par `arrow` au moment de la\nmatérialisation et, évidemment, les limites fixées à `duckdb` ne peuvent pas\ns'appliquer sur `arrow`.\n:::\n\n## Dernière étape d'optimisation\n\nPeut-on aller plus loin ? Oui mais pour ça il faut éviter de matérialiser les\ndonnées.\n\nIl y a deux solutions :\n\n### La solution `arrow::write_dataset()`\n\nLa première solution est d'utiliser `arrow::write_dataset()` à la place de\n`arrow::write_parquet()`. \n\nEn effet, contrairement à `write_parquet()`, `write_dataset()` sait lire les\ndonnées envoyées par la requête `dbplyr` au fur et à mesure tandis que\n`write_parquet` a besoin de la totalité des données pour les écrire.\n\nChanger les dernières lignes `write_dataset()` a un impact majeur :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequest %>%\n  to_arrow() %>%\n  write_dataset(\"dbplyr_parquet\")\n```\n:::\n\n\n::: {.callout-note}\nCe code prend autour de 100 secondes et consomme au pic 2Go de mémoire.\n:::\n\n### La solution \"full\" `duckdb`\n\nLa seconde solution est d'utiliser la commande native de `duckdb` pour générer\nles fichiers parquet : [`COPY ... TO\n...`](https://duckdb.org/docs/sql/statements/copy.html)\n\nSi vous êtes expert en SQL vous pouvez convertir mais ça n'est pas mon cas alors\nnous allons utiliser la fonction `dbplyr::sql_render()` et utiliser directement\nle SQL généré par `dbplyr` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsql <- request %>% \n  dbplyr::sql_render(con = con)\n```\n:::\n\n\nLa variable `sql` contient une requête :\n\n\n::: {.cell}\n\n```{.sql .cell-code}\n<SQL>\nSELECT\n  *,\n  CASE WHEN (carbu_det IN ('Diesel', 'Biodiesel', 'Diesel HNR', 'Diesel HR')) THEN 'Diesel (y compris hybrides)' WHEN NOT (carbu_det IN ('Diesel', 'Biodiesel', 'Diesel HNR', 'Diesel HR')) THEN 'Essence et autres énergies' END AS carbu_agreg,\n  CASE WHEN (carbu_simpl IN ('Diesel', 'Essence')) THEN 'Diesel et Essence thermiques' WHEN NOT (carbu_simpl IN ('Diesel', 'Essence')) THEN 'Autres énergies' END AS carbu_agreg2\nFROM (\n  SELECT\n    *,\n    CASE\nWHEN (puis_kw <= 55.0) THEN '1 - moins de 55 kw'[...]\n[...]\n```\n:::\n\n\nLe SQL est \"brutal\" mais :\n\n* nous ne sommes pas à un concours de beau code\n* l'optimisation c'est le boulot de `duckdb`\n\nNous allons enfin utiliser le SQL généré pour écrire le fichier :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbExecute(con, glue::glue(\"COPY ({DBI::SQL(request)}) TO 'test2.parquet'\"))\n```\n:::\n\n\nEt alors ?\n\n::: {.callout-note}\nCe code prend également autour de 100 secondes et consomme 1,7Go de mémoire en pic.\n:::\n\nOn aurait aussi pu partitionner par exemple sur `year` si cette variable était\nbeaucoup utilisée pour des `filter` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbExecute(con, glue::glue(\"COPY ({DBI::SQL(request)}) \n                          TO 'dataset_par_annee' (FORMAT PARQUET, PARTITION_BY (year))\"))\n```\n:::\n\n\nOn peut noter également que le fichier parquet généré par `duckdb` est 20% plus\ngros que celui de `arrow` (730Go contre 600).\n\nNous venons de passer le traitement de 15min et plus de 25Go à 100s et 1,7 ou\n2Go. On peut s'arrêter là pour aujourd'hui non ?\n\n## Discussion sur la conversion de `dplyr` à `dbplyr`\n\nLa conversion de ce traitement en `duckdb` a demandé un peu de travail\nessentiellement sur la partie manipulation des dates pour trouver les fonctions\nlubridate connues de `dbplyr`.\n\n\n::: {.cell}\n\n:::\n\n\nDerrière la scène j'ai créé une table `table` avec les deux colonnes nécessaires\nque j'ai enregistrée dans `duckdb` dans la table `dates` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndates\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  date_mise_en_cir  year\n  <date>           <int>\n1 2018-04-02        2022\n2 2020-11-29        2023\n```\n\n\n:::\n:::\n\n\nLe passage : \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndates |>\n  mutate(\n    annee_mise_en_cir = as.numeric(substr(date_mise_en_cir, 1, 4)),\n    age = as.numeric(difftime(as.IDate(paste0(year,\"-01-01\")), date_mise_en_cir, units=\"days\")/365.25)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  date_mise_en_cir  year annee_mise_en_cir   age\n  <date>           <int>             <dbl> <dbl>\n1 2018-04-02        2022              2018  3.75\n2 2020-11-29        2023              2020  2.09\n```\n\n\n:::\n:::\n\n\nest traduit en :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl(con, \"dates\") |>\n  mutate(annee_mise_en_cir = year(date_mise_en_cir)) |>\n  mutate(age = (as_date(paste0(year, \"-01-01\")) - date_mise_en_cir ) / 365.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [?? x 4]\n# Database: DuckDB v1.3.0 [unknown@Linux 6.1.0-37-amd64:R 4.5.0/:memory:]\n  date_mise_en_cir  year annee_mise_en_cir   age\n  <date>           <int>             <dbl> <dbl>\n1 2018-04-02        2022              2018  3.75\n2 2020-11-29        2023              2020  2.09\n```\n\n\n:::\n:::\n\n\nMais `dbplyr` a une particularité intéressante, quand il ne comprends pas un\nordre, il l'envoie tel quel à la base de données. Nous aurions pu nous appuyer\nsur ce mécanisme pour utiliser la fonction `make_date(year, month, day)` de\n`duckdb` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl(con, \"dates\") |>\n  mutate(annee_mise_en_cir = year(date_mise_en_cir)) |>\n  mutate(age = (make_date(year, 1L, 1L) - date_mise_en_cir ) / 365.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [?? x 4]\n# Database: DuckDB v1.3.0 [unknown@Linux 6.1.0-37-amd64:R 4.5.0/:memory:]\n  date_mise_en_cir  year annee_mise_en_cir   age\n  <date>           <int>             <dbl> <dbl>\n1 2018-04-02        2022              2018  3.75\n2 2020-11-29        2023              2020  2.09\n```\n\n\n:::\n:::\n\n\nVersion nettement plus facile à car faisant uniquement ce qu'il faut sans\n`substr`, `paste` et cie.\n\n## Peut-on utiliser uniquement `arrow` sur ce traitement ?\n\nBien sûr, comme pour le point précédent, il y a un travail sur la conversion car\n`arrow` :\n\n* ne gère pas les calculs sur les dates comme `dbplyr`\n* ne connait pas `base::cut()` qui est massivement employé.\n\nSur le premier point, une seule ligne à changer par rapport à notre code\n`dbplyr` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndates %>%\n  mutate(\n    annee_mise_en_cir = year(date_mise_en_cir),\n    age = (as_date(paste0(year, \"-01-01\")) - date_mise_en_cir ) / 365.25\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  date_mise_en_cir  year annee_mise_en_cir age          \n  <date>           <int>             <dbl> <drtn>       \n1 2018-04-02        2022              2018 3.750856 days\n2 2020-11-29        2023              2020 2.088980 days\n```\n\n\n:::\n:::\n\n\nArrow n'autorise pas à faire un calcul sur une différence entre deux dates, il\nfaut donc les convertir en jours (`as.integer(date)` va donner un nombre de\njours depuis le 1er janvier 1970) et ensuite on peut travailler dessus comme sur\ndes entiers :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndates |> as_arrow_table() |>\n  mutate(\n    annee_mise_en_cir = year(date_mise_en_cir),\n    age = (as.integer(as_date(paste0(year, \"-01-01\"))) - as.integer(date_mise_en_cir)) / 365.25\n  ) |>\n  collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  date_mise_en_cir  year annee_mise_en_cir   age\n  <date>           <int>             <int> <dbl>\n1 2018-04-02        2022              2018  3.75\n2 2020-11-29        2023              2020  2.09\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\nSur le second point, on peut remplacer `cut` par un `case_when`, soit :\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoids |>\n  mutate(\n    poids_vide_tr = cut(poids_vide,\n                      breaks=c(0,1000,1200,1500,1800,2000,Inf),\n                      include.lowest=TRUE,\n                      labels=c(\"1 - moins de 1000 kg\",\n                               \"2 - plus de 1 à 1,2 t\",\n                               \"3 - plus de 1,2 à 1,5 t\",\n                               \"4 - plus de 1,5 à 1,8 t\",\n                               \"5 - plus de 1,8 à 2 t\",\n                               \"6 - plus de 2 t\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  poids_vide poids_vide_tr          \n       <dbl> <fct>                  \n1         10 1 - moins de 1000 kg   \n2       3000 6 - plus de 2 t        \n3       1700 4 - plus de 1,5 à 1,8 t\n4       1300 3 - plus de 1,2 à 1,5 t\n```\n\n\n:::\n:::\n\n\nPar :\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoids |>\n  as_arrow_table() |>\n  mutate(\n    poids_vide_tr = case_when(\n      poids_vide <= 1000 ~ \"1 - moins de 1000 kg\",\n      poids_vide <= 1200 ~ \"2 - plus de 1 à 1,2 t\",\n      poids_vide <= 1500 ~ \"3 - plus de 1,2 à 1,5 t\",\n      poids_vide <= 1800 ~ \"4 - plus de 1,5 à 1,8 t\",\n      poids_vide <= 2000 ~ \"5 - plus de 1,8 à 2 t\",\n      poids_vide > 2000 ~ \"6 - plus de 2 t\")) |>\n  collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  poids_vide poids_vide_tr          \n       <dbl> <chr>                  \n1         10 1 - moins de 1000 kg   \n2       3000 6 - plus de 2 t        \n3       1700 4 - plus de 1,5 à 1,8 t\n4       1300 3 - plus de 1,2 à 1,5 t\n```\n\n\n:::\n:::\n\n\nÀ noter que :\n\n* la version `arrow::case_when()` ne supporte pas l'argument `.default` de `dplyr::case_when()`\n* `dbplyr` supporte également cette syntaxe et que la traduction SQL est la même que celle de `base::cut()`)\n* je trouve la syntaxe `case_when()` plus explicite, les limites sont en face du texte correspondant\n\nJe laisse au lecteur le soin de convertir l'ensemble du script. \n\n::: {.callout-note}\nEn utilisant `write_dataset()` pour écrire les données, le traitement met 80\nsecondes et utilise 15Go de mémoire.\n:::\n\n## Conclusions\n\nNous avons réussi à diviser d'un facteur 10 le temps de traitement et la mémoire\nutilisée avec un investissement en temps raisonnable et surtout en rendant le\ncode beaucoup plus lisible. En passant, il peut être intéressant de passer par\ndes fonctions `duckdb`.\n\nIl est même tout à fait envisageable dans le cas présent et avec les deux\nversions `duckdb` de traiter l'ensemble des fichiers en une seule passe. Le test\nmontre que, en augmentant la limite de mémoire allouée à `duckdb` à 15Go, ce qui\nreste très raisonnable, les deux méthodes permettent de traiter d'un bloc\nl'ensemble des fichiers en 12min en utilisant autour de 12Go de mémoire.\n\nLa version \"full\" `arrow` met à peu près le même temps mais consomme 150Go de\nmémoire en pic !\n\nEt pour finir : le traitement utilisant uniquement `duckdb` permet de mieux\nmaîtriser la consommation mémoire au prix d'un ralentissement important quand il\narrive à la limite fixée. En fixant une limite à 10Go à `duckdb` pour traiter\nl'ensemble des fichiers en une seule passe, le temps de traitement passe à 45\nmin soit 3 fois le temps qu'il faudrait pour traiter les fichiers séparément\n(`duckdb` écrit des données temporaires sur disque, ce qui est beaucoup plus\nlent que de travailler en mémoire). **Pour traiter des fichiers particulièrement\nvolumineux, il peut dont être intéressant de continuer à séparer les calculs.**\n\n:::callout-tip\n## Quand vos données sont volumineuses\n\n1. utilisez `tbl()` ou `arrow::open_dataset()` plutôt que\n`arrow::read_parquet()`\n1. utilisez `duckdb`/`dbplyr` ou `arrow` plutôt que `dplyr`\n1. quand vous avez des jointures sur des grosses tables, utilisez\n`duckdb`/`dbplyr` plutôt que `arrow`\n1. utilisez `arrow::write_dataset()` ou `COPY ... TO ...` plutôt\n`arrow::write_parquet()`\n1. si ces outils repoussent (beaucoup) les limites, ils ne sont pas magiques :\nil peut encore être intéressant de scinder des calculs en plusieurs blocs pour\nles accélérer voire les rendre possibles.\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}